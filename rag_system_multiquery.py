"""
LangChain MultiQueryRetriever ê¸°ë°˜ ê³ ê¸‰ RAG ì‹œìŠ¤í…œ
ê²€ìƒ‰ ì •í™•ë„ ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ ë‹¤ì¤‘ ì§ˆë¬¸ ìƒì„± ë° ê²€ìƒ‰
"""
import pandas as pd
import os
import warnings
from typing import List, Dict, Any
import pickle
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
warnings.filterwarnings("ignore")

try:
    # LangChain í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
    from langchain_community.vectorstores import FAISS
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain.docstore.document import Document
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain.retrievers.multi_query import MultiQueryRetriever
    from langchain.prompts import PromptTemplate
    
    LANGCHAIN_AVAILABLE = True
    print("LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    print(f"LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
    LANGCHAIN_AVAILABLE = False

class MultiQueryRAGSystem:
    def __init__(self, csv_path: str = "data/school_info.csv"):
        """
        MultiQuery RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        """
        if not LANGCHAIN_AVAILABLE:
            raise ImportError("LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.csv_path = csv_path
        self.vectorstore = None
        self.basic_retriever = None
        self.multi_query_retriever = None
        self.llm = None
        self.documents = None
        self.embedding_model = None
        
        # ì €ì¥ ê²½ë¡œ
        self.vectorstore_path = "vectorstore_multiquery"
        
        print("MultiQuery RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
        self.initialize_system()
    
    def load_and_prepare_documents(self):
        """CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  Document í˜•íƒœë¡œ ë³€í™˜"""
        try:
            print("CSV ë°ì´í„° ë¡œë“œ ì¤‘...")
            df = pd.read_csv(self.csv_path)
            print(f"ì´ {len(df)}ê°œì˜ ë°ì´í„° ë¡œë“œë¨")
            
            documents = []
            for idx, row in df.iterrows():
                # ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìì—°ìŠ¤ëŸ½ê²Œ ê²°í•©
                content = f"ì§ˆë¬¸: {row['question']}\në‹µë³€: {row['answer']}"
                
                metadata = {
                    'source': f"school_info_{idx}",
                    'question': str(row['question']),
                    'answer': str(row['answer']),
                    'id': idx
                }
                
                doc = Document(page_content=content, metadata=metadata)
                documents.append(doc)
            
            self.documents = documents
            print(f"{len(documents)}ê°œì˜ Document ìƒì„± ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def setup_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì„¤ì •"""
        try:
            # OpenAI ì„ë² ë”© ì‹œë„
            print("OpenAI ì„ë² ë”© ëª¨ë¸ ì„¤ì • ì¤‘...")
            self.embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")
            print("OpenAI ì„ë² ë”© ì„¤ì • ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"OpenAI ì„ë² ë”© ì‹¤íŒ¨: {e}")
            try:
                print("HuggingFace ì„ë² ë”©ìœ¼ë¡œ ëŒ€ì²´...")
                self.embedding_model = HuggingFaceEmbeddings(
                    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
                )
                print("HuggingFace ì„ë² ë”© ì„¤ì • ì™„ë£Œ")
                return True
            except Exception as e2:
                print(f"ì„ë² ë”© ëª¨ë¸ ì„¤ì • ì™„ì „ ì‹¤íŒ¨: {e2}")
                return False
    
    def create_or_load_vectorstore(self):
        """ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë˜ëŠ” ë¡œë“œ"""
        try:
            # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„
            if os.path.exists(self.vectorstore_path):
                try:
                    print("ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹œë„...")
                    self.vectorstore = FAISS.load_local(
                        self.vectorstore_path, 
                        self.embedding_model,
                        allow_dangerous_deserialization=True
                    )
                    print("ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ")
                    return True
                except Exception as e:
                    print(f"ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            print("ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
            self.vectorstore = FAISS.from_documents(
                documents=self.documents,
                embedding=self.embedding_model
            )
            
            # ì €ì¥
            self.vectorstore.save_local(self.vectorstore_path)
            print("ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def setup_llm(self):
        """LLM ì„¤ì • (ì„ íƒì‚¬í•­)"""
        try:
            self.llm = ChatOpenAI(
                model="gpt-4o-mini",
                temperature=0.2,
                max_tokens=500
            )
            print("LLM ì„¤ì • ì™„ë£Œ - MultiQuery ê¸°ëŠ¥ í™œì„±í™”")
            return True
        except Exception as e:
            print(f"LLM ì„¤ì • ì‹¤íŒ¨: {e}")
            print("MultiQuery ê¸°ëŠ¥ì€ ë¹„í™œì„±í™”ë˜ì§€ë§Œ ê¸°ë³¸ ê²€ìƒ‰ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
            self.llm = None
            return True  # LLM ì—†ì´ë„ ê³„ì† ì§„í–‰
    
    def setup_retrievers(self):
        """ê²€ìƒ‰ê¸°ë“¤ ì„¤ì •"""
        try:
            # ê¸°ë³¸ ê²€ìƒ‰ê¸° (ì„ê³„ê°’ ë‚®ì¶¤)
            self.basic_retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 8}  # ì„ê³„ê°’ ì œê±°í•˜ê³  ìƒìœ„ 8ê°œë§Œ
            )
            print("ê¸°ë³¸ ê²€ìƒ‰ê¸° ì„¤ì • ì™„ë£Œ")
            
            # MultiQuery ê²€ìƒ‰ê¸° ì„¤ì • (LLMì´ ìˆì„ ë•Œë§Œ)
            if self.llm:
                # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ìƒì„±
                multi_query_prompt = PromptTemplate(
                    input_variables=["question"],
                    template="""ë‹¹ì‹ ì€ í•™êµ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì§ˆë¬¸ë“¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì›ë³¸ ì§ˆë¬¸: {question}

ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ê´€ì ì—ì„œ 3-4ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ê²€ìƒ‰ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
1. ì§ì ‘ì ì¸ ì§ˆë¬¸
2. ê´€ë ¨ ë‹´ë‹¹ìë‚˜ ë¶€ì„œ ì •ë³´
3. ì—°ë½ì²˜ë‚˜ ìœ„ì¹˜ ì •ë³´  
4. ê´€ë ¨ ì—…ë¬´ë‚˜ ì ˆì°¨

ê° ì§ˆë¬¸ì€ ê°œí–‰ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”."""
                )
                
                self.multi_query_retriever = MultiQueryRetriever.from_llm(
                    retriever=self.basic_retriever,
                    llm=self.llm,
                    prompt=multi_query_prompt
                )
                print("MultiQuery ê²€ìƒ‰ê¸° ì„¤ì • ì™„ë£Œ")
            else:
                print("LLMì´ ì—†ì–´ MultiQuery ê²€ìƒ‰ê¸°ë¥¼ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            return True
            
        except Exception as e:
            print(f"ê²€ìƒ‰ê¸° ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def initialize_system(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        steps = [
            ("ë°ì´í„° ë¡œë“œ", self.load_and_prepare_documents),
            ("ì„ë² ë”© ì„¤ì •", self.setup_embeddings),
            ("ë²¡í„°ìŠ¤í† ì–´ ìƒì„±", self.create_or_load_vectorstore),
            ("LLM ì„¤ì •", self.setup_llm),
            ("ê²€ìƒ‰ê¸° ì„¤ì •", self.setup_retrievers)
        ]
        
        for step_name, step_func in steps:
            print(f"\n[{step_name}] ì§„í–‰ ì¤‘...")
            if not step_func():
                raise Exception(f"{step_name} ì‹¤íŒ¨")
            print(f"[{step_name}] ì™„ë£Œ")
        
        print("\nğŸ‰ MultiQuery RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def search_documents(self, query: str, use_multi_query: bool = True) -> List[Document]:
        """ë¬¸ì„œ ê²€ìƒ‰ (ìƒˆ API ì‚¬ìš©)"""
        try:
            if use_multi_query and self.multi_query_retriever:
                print(f"MultiQuery ê²€ìƒ‰ ì‹¤í–‰: '{query}'")
                docs = self.multi_query_retriever.invoke({"input": query})
                print(f"MultiQuery ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ ë¬¸ì„œ")
            else:
                print(f"ê¸°ë³¸ ê²€ìƒ‰ ì‹¤í–‰: '{query}'")
                docs = self.basic_retriever.invoke(query)
                print(f"ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ ë¬¸ì„œ")
            
            return docs
        except Exception as e:
            print(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # í´ë°±ìœ¼ë¡œ ì§ì ‘ ìœ ì‚¬ë„ ê²€ìƒ‰
            try:
                if self.vectorstore:
                    docs_and_scores = self.vectorstore.similarity_search_with_score(query, k=5)
                    docs = [doc for doc, score in docs_and_scores if score < 1.0]  # ìŠ¤ì½”ì–´ í•„í„°
                    print(f"í´ë°± ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ ë¬¸ì„œ")
                    return docs
            except Exception as e2:
                print(f"í´ë°± ê²€ìƒ‰ë„ ì‹¤íŒ¨: {e2}")
            return []
    
    def get_answer(self, query: str, use_multi_query: bool = True, max_results: int = 3) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±"""
        if not query.strip():
            return {
                'results': [{'answer': 'ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.', 'confidence': 0.0}],
                'method': 'none',
                'query': query
            }
        
        try:
            # ë¬¸ì„œ ê²€ìƒ‰
            docs = self.search_documents(query, use_multi_query)
            
            if not docs:
                return {
                    'results': [{'answer': 'ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'confidence': 0.0}],
                    'method': 'multi_query' if use_multi_query else 'basic',
                    'query': query
                }
            
            # ê²°ê³¼ ì •ë¦¬
            results = []
            seen_answers = set()
            
            for i, doc in enumerate(docs[:max_results * 2]):
                try:
                    answer = doc.metadata.get('answer', doc.page_content)
                    question = doc.metadata.get('question', '')
                    
                    # ì¤‘ë³µ ì œê±°
                    if answer in seen_answers:
                        continue
                    seen_answers.add(answer)
                    
                    # ì‹ ë¢°ë„ ê³„ì‚° (ìˆœì„œ ê¸°ë°˜)
                    confidence = max(0.95 - i * 0.1, 0.2)
                    
                    results.append({
                        'answer': answer,
                        'confidence': confidence,
                        'question': question,
                        'source': doc.metadata.get('source', ''),
                        'preview': doc.page_content[:80] + "..."
                    })
                    
                    if len(results) >= max_results:
                        break
                        
                except Exception as e:
                    print(f"ê²°ê³¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                    continue
            
            # ìµœì†Œ 1ê°œ ê²°ê³¼ ë³´ì¥
            if not results and docs:
                first_doc = docs[0]
                results.append({
                    'answer': first_doc.metadata.get('answer', 'ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'),
                    'confidence': 0.5,
                    'question': first_doc.metadata.get('question', ''),
                    'source': first_doc.metadata.get('source', ''),
                    'preview': first_doc.page_content[:80] + "..."
                })
            
            return {
                'results': results,
                'method': 'multi_query' if use_multi_query else 'basic',
                'query': query,
                'total_docs': len(docs)
            }
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'results': [{'answer': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}', 'confidence': 0.0}],
                'method': 'error',
                'query': query
            }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
multiquery_rag = None

def initialize_rag():
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    global multiquery_rag
    if multiquery_rag is None:
        multiquery_rag = MultiQueryRAGSystem()
    return multiquery_rag

def get_rag_answer(query: str, use_multi_query: bool = True) -> Dict[str, Any]:
    """ë‹µë³€ ìƒì„±"""
    rag = initialize_rag()
    return rag.get_answer(query, use_multi_query=use_multi_query)

if __name__ == "__main__":
    print("=== MultiQuery RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
    
    test_queries = [
        "í•™ë…„ì—…ë¬´",
        "ë…¸ì£¼ì˜", 
        "êµì¥ì„ ìƒë‹˜",
        "íŒ©ìŠ¤",
        "8401",
        "1-1ë°˜",
        "ì²´ìœ¡ì„ ìƒë‹˜"
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: '{query}'")
        print("-" * 60)
        
        result = get_rag_answer(query, use_multi_query=True)
        
        print(f"ê²€ìƒ‰ ë°©ë²•: {result['method']}")
        if 'total_docs' in result:
            print(f"ì°¾ì€ ë¬¸ì„œ ìˆ˜: {result['total_docs']}ê°œ")
        
        for i, res in enumerate(result['results'][:2], 1):
            print(f"\nğŸ“‹ ë‹µë³€ {i}:")
            print(f"  ë‚´ìš©: {res['answer']}")
            print(f"  ì‹ ë¢°ë„: {res['confidence']:.2f}")
            if res.get('question'):
                print(f"  ì›ë³¸ì§ˆë¬¸: {res['question']}")